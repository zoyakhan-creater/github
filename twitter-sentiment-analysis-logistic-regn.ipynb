{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2231927,"sourceType":"datasetVersion","datasetId":1340873}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Twitter Sentiment Analysis**","metadata":{"id":"qs5K6z9fJlpR"}},{"cell_type":"markdown","source":"**1) Importing Packages**","metadata":{"id":"5uK8trjuKTXN"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport re\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"id":"R76NlA9fJlZ9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2) Importing Dataset**","metadata":{"id":"UsQ3-LAXOLDe"}},{"cell_type":"code","source":"# Loading the data into dataframe\ndf = pd.read_csv('/kaggle/input/twitter-sentiment-dataset/Twitter_Data.csv')","metadata":{"id":"m3umOU-5KPwG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3) Analysing the Data**","metadata":{"id":"gaGjFBIqOT9k"}},{"cell_type":"code","source":"# Looking at data\ndf.sample(5)","metadata":{"id":"zP7FXytIKR-Q","outputId":"35451c33-3877-41d5-c8e4-b7ae6018b756","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of rows and columns\ndf.shape","metadata":{"id":"oUGf9W6BL1zb","outputId":"fd2b7ebf-05fe-4a27-a576-52f51df6d211","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Deatiled information about data\ndf.info()","metadata":{"id":"B90OB2F1L4i4","outputId":"d9e5036c-2545-4825-8248-66bf3ecd9259","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the missing values\ndf.isnull().sum()","metadata":{"id":"k4IMPqylL62g","outputId":"a55a66c5-ea78-4114-9bd9-33b45f41e391","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the values from dataframe\ndf = df.dropna()","metadata":{"id":"IhlTIm9hL9wZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the distribution of category\ndf['category'].value_counts()","metadata":{"id":"CsTbjL4fMAIu","outputId":"e2b7ee3d-fab1-409d-c052-f8d8f38c63fc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the categories distribution in percentage\nplt.figure(figsize=[4, 4])\nplt.pie(df['category'].value_counts(), labels=df['category'].value_counts().index, autopct='%1.1f%%')\nplt.title('Percentage share: Positive Tweet vs Negative Tweet vs Neutral Tweet')\nplt.show()","metadata":{"id":"uxoMAijKMCjD","outputId":"256430e9-46e7-4f2c-bba7-8fdf90349e51","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4) Data Preprocessing**","metadata":{"id":"4mTDcvw0OiqY"}},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords', quiet=True)","metadata":{"id":"TBIFnnst0a9i","outputId":"2ff0c800-0ab2-4d0f-b6d2-ae52dc7b9608","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pattern =re.compile('[^a-zA-Z]')\n\nenglish_stopwords = stopwords.words('english')\n\nport_stemmer = PorterStemmer()","metadata":{"id":"nfMA2mpxgtxE","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessed_text(text):\n\n  stemmed_content = re.sub(pattern,' ',text)\n  stemmed_content = stemmed_content.lower()\n\n  stemmed_content = stemmed_content.split()\n\n  stemmed_content = [port_stemmer.stem(word) for word in stemmed_content if not word in english_stopwords]\n  stemmed_content = ' '.join(stemmed_content)\n\n\n  return stemmed_content","metadata":{"id":"iAfYtVUMgxPX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying the function\ndf['stemmed_content'] = df['clean_text'].apply(preprocessed_text)","metadata":{"id":"dHF5-e8nMM25","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"8AtVSQQ4MOpP","outputId":"78c55d26-9b32-4828-b65e-f5e41fa928f5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5) Data Visualization**","metadata":{"id":"IlvqOLlkOqdB"}},{"cell_type":"code","source":"# Segrating based on different sentiments\ndf_negative = df[df[\"category\"]==-1]\ndf_positive = df[df[\"category\"]==1]\ndf_neutral = df[df[\"category\"]==0]","metadata":{"id":"CmHzyscsMQ1D","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud,STOPWORDS","metadata":{"id":"IAa8_DejMS-j","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the overall frequent words\nall_words_raw = \" \".join([sentence for sentence in df['clean_text']])\nall_words_processed = \" \".join([sentence for sentence in df['stemmed_content']])\n\nwordcloud_raw = WordCloud(width=800, height=400, random_state=21, max_font_size=110).generate(all_words_raw)\nwordcloud_processed = WordCloud(width=800, height=400, random_state=21, max_font_size=110).generate(all_words_processed)\n\n# Plot the word clouds in a single figure with subplots\nfig, axes = plt.subplots(1, 2, figsize=(20, 10))\n\n# Plot the raw text word cloud\naxes[0].imshow(wordcloud_raw, interpolation='bilinear')\naxes[0].set_title('Word Cloud Before Preprocessing', fontsize=20)\naxes[0].axis('off')\n\n# Plot the processed text word cloud\naxes[1].imshow(wordcloud_processed, interpolation='bilinear')\naxes[1].set_title('Word Cloud After Preprocessing', fontsize=20)\naxes[1].axis('off')\n\nplt.show()","metadata":{"id":"UwB7BnKw4daq","outputId":"45ff21ea-88eb-4453-bd26-1c93f237f5ac","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the frequent words for positive tweets\nall_words_raw_positive = \" \".join([sentence for sentence in df_positive['clean_text']])\nall_words_processed_positive = \" \".join([sentence for sentence in df_positive['stemmed_content']])\n\nwordcloud_raw_positive = WordCloud(width=800, height=400, random_state=21, max_font_size=110, background_color='white').generate(all_words_raw_positive)\nwordcloud_processed_positive = WordCloud(width=800, height=400, random_state=21, max_font_size=110, background_color='white').generate(all_words_processed_positive)\n\n# Plot the word clouds in a single figure with subplots\nfig, axes = plt.subplots(1, 2, figsize=(20, 10))\n\n# Plot the raw text word cloud\naxes[0].imshow(wordcloud_raw_positive, interpolation='bilinear')\naxes[0].set_title('Word Cloud for Positive Tweets Before Preprocessing', fontsize=20)\naxes[0].axis('off')\n\n# Plot the processed text word cloud\naxes[1].imshow(wordcloud_processed_positive, interpolation='bilinear')\naxes[1].set_title('Word Cloud for Positive Tweets After Preprocessing', fontsize=20)\naxes[1].axis('off')\n\nplt.show()","metadata":{"id":"UXeiwKkl5rJt","outputId":"a8b87fce-f181-4f61-ccdc-7500a843f0bd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the frequent words for negative tweets\nall_words_raw_negative = \" \".join([sentence for sentence in df_negative['clean_text']])\nall_words_processed_negative = \" \".join([sentence for sentence in df_negative['stemmed_content']])\n\nwordcloud_raw_negative = WordCloud(width=800, height=400, random_state=21, max_font_size=110).generate(all_words_raw_negative)\nwordcloud_processed_negative = WordCloud(width=800, height=400, random_state=21, max_font_size=110).generate(all_words_processed_negative)\n\n# Plot the word clouds in a single figure with subplots\nfig, axes = plt.subplots(1, 2, figsize=(20, 10))\n\n# Plot the raw text word cloud\naxes[0].imshow(wordcloud_raw_negative, interpolation='bilinear')\naxes[0].set_title('Word Cloud for Negative Tweets Before Preprocessing', fontsize=20)\naxes[0].axis('off')\n\n# Plot the processed text word cloud\naxes[1].imshow(wordcloud_processed_negative, interpolation='bilinear')\naxes[1].set_title('Word Cloud for Negative Tweets After Preprocessing', fontsize=20)\naxes[1].axis('off')\n\nplt.show()","metadata":{"id":"fVW0YKO06hJ5","outputId":"e20f6684-7c42-4fd2-bb63-000c3f37fe25","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize the frequent words for neutral tweets\nall_words_raw_neutral = \" \".join([sentence for sentence in df_neutral['clean_text']])\nall_words_processed_neutral = \" \".join([sentence for sentence in df_neutral['stemmed_content']])\n\nwordcloud_raw_neutral = WordCloud(width=800, height=400, random_state=21, max_font_size=110, background_color='white').generate(all_words_raw_neutral)\nwordcloud_processed_neutral = WordCloud(width=800, height=400, random_state=21, max_font_size=110, background_color='white').generate(all_words_processed_neutral)\n\n# Plot the word clouds in a single figure with subplots\nfig, axes = plt.subplots(1, 2, figsize=(20, 10))\n\n# Plot the raw text word cloud\naxes[0].imshow(wordcloud_raw_neutral, interpolation='bilinear')\naxes[0].set_title('Word Cloud for Neutral Tweets Before Preprocessing', fontsize=20)\naxes[0].axis('off')\n\n# Plot the processed text word cloud\naxes[1].imshow(wordcloud_processed_neutral, interpolation='bilinear')\naxes[1].set_title('Word Cloud for Neutral Tweets After Preprocessing', fontsize=20)\naxes[1].axis('off')\n\nplt.show()","metadata":{"id":"CFiugXWZ5rPP","outputId":"322c28ef-fd0a-4c7c-e735-324d729697ea","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6) Splitting Input Matrix Feature and Target Feature**","metadata":{"id":"4KvPQ0KDPOhZ"}},{"cell_type":"code","source":"# Separating the data and label\nX = df['stemmed_content']\ny = df['category']","metadata":{"id":"Q0o8a0BaMesY","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2)","metadata":{"id":"k-5hiLszMhV4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**7) Feature Extraction**","metadata":{"id":"Y09yYKBoO-a_"}},{"cell_type":"code","source":"# Converting textual data into numerical\nvectorizer = TfidfVectorizer()\n\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)","metadata":{"id":"3CBXqOu-MjVf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**8) Model Training**","metadata":{"id":"FgqiwiaVPc8Z"}},{"cell_type":"code","source":"# Logistic Regression model\nlr = LogisticRegression(max_iter=1000)\n\n# Fit\nlr.fit(X_train_tfidf, y_train)\n\n# Predictions\ny_pred = lr.predict(X_test_tfidf)","metadata":{"id":"0Sdvqg-XMll_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**9) Model Evaluation Metrics**","metadata":{"id":"eJ0C1oXiPzpZ"}},{"cell_type":"code","source":"# Calculate the accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy:.2f}')","metadata":{"id":"YHDe8uF5MpWm","outputId":"d9353214-13b4-447b-ea8d-95ed1a348e04","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the classification report\nprint('Classification Report:')\nprint(classification_report(y_test, y_pred))","metadata":{"id":"MHZILH-JMrHw","outputId":"c83a6ecb-ab4b-49a2-85c0-e5226a98708d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the confusion matrix\nprint('Confusion Matrix:')\nprint(confusion_matrix(y_test, y_pred))","metadata":{"id":"eXROArUxMs-O","outputId":"221e8c31-59a8-4bf6-8044-d813e752c49a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**10) Saving the model**","metadata":{"id":"kXl_ceNfP6E9"}},{"cell_type":"code","source":"import pickle\nfilename = 'tweet_lr_model.pkl'\npickle.dump(lr, open(filename, 'wb'))","metadata":{"id":"PCUDD0G7MvGj","trusted":true},"execution_count":null,"outputs":[]}]}